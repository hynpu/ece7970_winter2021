# Citation
Rossen, B., & Lok, B. (2012). A crowdsourcing method to develop virtual human conversational agents. International Journal of Human Computer Studies, 70(4), 301–319. https://doi.org/10.1016/j.ijhcs.2011.11.004

# Abstract

In the traditional training process, the CCM, to develop robust natural language conversational models, engineers need to collect the knowledge from experts and students, and then generate the machine readable corpus from these knowledge. As a result of such extensive domain expert and knowledge engineer time requirements, the engineers are unable to create this big amount of scenarios.

So, the process is: recording, asking, and interactions. Here, the bottle neck is the knowledge engineer, because it cannot perform well with the increase of data complexity.

In the systme HDCM proposed in this paper, there will be a learning system for experts and students to input their knowledge directly (LfD). The expert enters an initial set of questions and responses (outline of the conversation). Then, the expert enlists the help of novices. 

When a student first interacts with the system, it will perform very poorly, while the system will log the error, and these errors will be viewed by experts later. Based on these errors, the expert then enters new responses to each new stimulus, or matches new stimuli to existing responses.
Using HDCM, domain experts and novices asynchronously collaborate to teach the VH how to converse.

# Spotlight 

Time efficiency improvement:　By shortening the iteration cycle and easing the distribution, we shorten the time to create a VH and increase the potential for these systems to be used in the real world.

Case-based reasoning systems learn by identifying successes and fail- ures in order to solve *similar* problems in the future.

# What to learn 

Can we also try to implement the decentralized LfD on the SAR?