Hi Dr. Louie,
In the past week, I mainly focus on the Udacity course study and go through the following topics.

Generalization of RL
    Features of action -> Linear value function approximation

Partially observed MDP
    POMDP
    Bayesian in RL
    PSR theorem
I didn't quite understand this lesson, since there are too many prerequisites about probability and statistics. Also, I think this lesson can be expanded to a pretty large topic, and the lecturer only gave a very generalized introduction

Markov options
    Semi MDP
    Modular RL
    Monte Carlo tree search

Basic concepts about Game Theory, including:
    Prisoner's dilemma
    Pure strategy vs mixed strategy
    Nash equilibrium
 
Based on the course study, I think some of the basic ideas and concepts related to RL and MDP are clear to me now, such as how Q learning works. But some of the topics I am still feeling confused about, or not quite understand their meaning\application. But I think I will know them better once I started to read more research papers or do the projects myself.

Also, could you please send me some RL projects for beginners, so that I could start some hands-on practice, and read the library code to understand how the code works?

Here are several projects I found, but I am not sure if they are friendly for beginners, or if the project is well organized.
http://ai.berkeley.edu/project_overview.html
https://github.com/openai/spinningup

Thank you,
Hao
